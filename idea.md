Pick Approach 1 – “The AI Architect”, re-package the sample “Executive Insight Dashboard” idea into a “Zero-Touch Support Insights & Forecasting Bot.”
• All logic lives in 15–20 lines of SQL that call AI.GENERATE_TABLE and AI.FORECAST, so coding is trivial.
• You can reuse Google’s public “Google Analytics Sample” or “Call-Center Complaint” datasets—no data wrangling.
• A single Looker Studio dashboard + a short Loom recording satisfies the presentation requirements.
Result: you hit every rubric bullet while spending < 2 days of real work.
Why this is the lowest-effort, highest-score path
No infrastructure work
All heavy lifting (LLM inference, time-series models) is done by built-in BigQuery AI functions; you never stand up a model, an index, or Cloud Storage buckets.
Direct alignment with the judging rubric
• Technical Implementation → BigQuery AI is the core of the solution (full 15 pts).
• Innovation/Impact → Auto-summarising live support logs saves clear $$ (up to 15 pts).
• Demo/Presentation → A single dashboard that updates in real time + concise write-up earns the 20 pts in this section.
• Assets → Publish the tiny SQL script to GitHub and embed it in a Kaggle notebook (10 pts).
Leverages a hackathon-supplied inspiration
The prompt itself calls out an “Executive ‘Insight’ Dashboard” as an example judges already think it’s a good use case.
The Idea: “Zero-Touch Support Insights & Forecasting Bot”
Problem
Managers drown in raw chat / e-mail / call transcripts and miss systemic issues.
Solution
Daily summarisation
text


CREATE OR REPLACE TABLE project.dataset.daily_insights AS
SELECT
  DATE(created_at)  AS event_date,
  AI.GENERATE_TABLE(
    'Summarise these tickets. Return three columns: summary, top_root_cause, sentiment (positive/neutral/negative).',
    STRUCT(ARRAY_AGG(text) AS text_blob)
  ) AS (summary STRING, root_cause STRING, sentiment STRING)
FROM project.dataset.raw_tickets
GROUP BY 1;
Volume & sentiment forecast
text


CREATE OR REPLACE TABLE project.dataset.ticket_forecast AS
SELECT *
FROM ML.FORECAST(
  MODEL project.dataset.ts_model,
  STRUCT(30 AS horizon)
);
Looker Studio dashboard
• Panel 1: today’s autogenerated summaries + root causes
• Panel 2: 30-day ticket-volume forecast
• Panel 3: sentiment trend line
Optional one-liner: add semantic similarity search (Approach 2) to surface the “top 3 past tickets that match today’s dominant root cause” with VECTOR_SEARCH.
Deliverables checklist (minimal effort version)
Kaggle Write-up
• Problem Statement, Impact, Architecture diagram (drag-and-drop from Draw-io).
Public Notebook
• Contains exactly the two SQL snippets above plus a README cell.
GitHub repo
• README.md, sql/01_create_tables.sql, dashboard JSON export.
(Optional but fast) 2-minute Loom video
• Screen-share the dashboard; no editing required.
User Survey text file
• Fill in three bullet answers—earns the bonus 10 pts in under 5 minutes.
Effort estimate
• Data loading: 1 hour (public dataset is ready).
• SQL authoring & testing: 2 hours.
• Looker Studio dashboard: 1 hour.
• Write-up + GitHub push: 1 hour.
• Record Loom & complete survey: 30 minutes.
≈ 6 real hours of work → competitive entry in every rubric category.
Good luck—go claim that “Best in Generative AI” prize!

---
Use a built-in public dataset (fastest)
The Austin 311 help-desk archive is already hosted in BigQuery and looks a lot like support tickets.
sql


-- Step 1: Create an empty dataset to hold your hackathon tables
CREATE SCHEMA IF NOT EXISTS your_project.support_demo;

-- Step 2: Materialise the public 311 requests as “raw_tickets”
CREATE OR REPLACE TABLE your_project.support_demo.raw_tickets AS
SELECT
  CAST(created_date AS TIMESTAMP) AS created_at,
  description                          AS text
FROM `bigquery-public-data.austin_311.311_service_requests`
WHERE description IS NOT NULL;
